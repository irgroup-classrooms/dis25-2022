{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tutorial 3: Wordnet\n",
    "(Syn-)Semantic networks like WordNet are important resources for NLP. In this tutorial you will use basic functionalities of WordNet and the German variant GermaNet. Use the documentation for WordNet (https://www.nltk.org/howto/wordnet.html) and GermaNet (https://germanetpy.readthedocs.io/en/latest/). If you get stuck with the API documentation, use other documentation and help like stackoverflow.com or tutorials.\n",
    "\n",
    "## Task 1: Importing modules and data\n",
    "### a: Import NLP modules\n",
    "Import Pandas, Numpy, NLTK and RE as in the first tutorial and import them WordNet (as wn) from nltk.corpus.\n",
    "### b: Import of \"Quality-of-Life Modules\n",
    "Often modules are not necessary, but make it easier to work with larger corpora. Install them pandarallel. As in the first tutorial, import the method pandarallel (for parallelization in pandas) and initialize it with pandarallel.initialize(). You can now use parallel\\_apply() instead of the pandas method apply() for parallelizable tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas 1.3.4\n",
      "numpy 1.22.3\n",
      "nltk 3.7\n",
      "re 2.2.1\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import pandas as pd\n",
    "print (\"pandas\", pd.__version__)\n",
    "\n",
    "import numpy as np\n",
    "print (\"numpy\", np.__version__)\n",
    "\n",
    "import nltk\n",
    "print (\"nltk\", nltk.__version__)\n",
    "\n",
    "import re\n",
    "print (\"re\", re.__version__)\n",
    "\n",
    "from pandarallel import pandarallel  # parallelization\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Importing the data\n",
    "A data set on biased words (words that carry bias or unobjective value) is provided for the WordNet tutorial. Import the data frame \"data.pkl\" saved as a pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=ec9ca85e-1d5a-415b-a72e-e9dd284ea9a7 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('ec9ca85e-1d5a-415b-a72e-e9dd284ea9a7').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>topic</th>\n",
       "      <th>Label_bias</th>\n",
       "      <th>biased_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YouTube is making clear there will be no “birtherism” on its platform during this year’s U.S. presidential election – a belated response to a type of conspiracy theory more prevalent in the 2012 race.</td>\n",
       "      <td>elections-2020</td>\n",
       "      <td>Biased</td>\n",
       "      <td>[belated, birtherism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The increasingly bitter dispute between American women’s national soccer team and the U.S. Soccer Federation spilled onto the field Wednesday night when players wore their warm-up jerseys inside outin a protest before their 3-1 victory over Japan.</td>\n",
       "      <td>sport</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>[bitter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So while there may be a humanitarian crisis driving more vulnerable people to seek asylum in the United States, there is no security crisis.</td>\n",
       "      <td>immigration</td>\n",
       "      <td>Biased</td>\n",
       "      <td>[crisis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A professor who teaches climate change classes — a subject some would question as a legitimate area of study — said she has seen students who suffer fear, grief, stress, and anxiety about the future.</td>\n",
       "      <td>environment</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>[legitimate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking around the United States, there is never enough welfare for the left to stop killing developing humans in utero—solidly Democratic states lead the nation in abortion rates.</td>\n",
       "      <td>abortion</td>\n",
       "      <td>Biased</td>\n",
       "      <td>[killing, never, developing, humans, enough]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>In every case legislators are being swarmed by right-wing activists who don’t hesitate to use deceit and hysteria to stop Equal Rights Amendment (ERA) ratification from happening.</td>\n",
       "      <td>gender</td>\n",
       "      <td>Biased</td>\n",
       "      <td>[deceit, hysteria, swarmed, right-wing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>Polls show the transgender ideology is deeply unpopular, especially among women and parents.</td>\n",
       "      <td>gender</td>\n",
       "      <td>Biased</td>\n",
       "      <td>[ideology, unpopular]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>Democrats and Republicans stood and applauded after Illinois Rep. Rodney Davis, the top Republican on the House Administration Committee, saluted Haaland for making history as the first Native American woman to preside over the chamber.</td>\n",
       "      <td>gender</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>[saluted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>As a self-described Democratic socialist, Sen. Bernie Sanders, I-Vt., has been outspoken about economic inequality.</td>\n",
       "      <td>middle-class</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>[outspoken]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>During the segment, Colbert also bemoaned the fact that Barack Obama is no longer president.</td>\n",
       "      <td>white-nationalism</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>[bemoaned]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "                                               sentence              topic  \\\n",
       "0     YouTube is making clear there will be no “birt...     elections-2020   \n",
       "1     The increasingly bitter dispute between Americ...              sport   \n",
       "2     So while there may be a humanitarian crisis dr...        immigration   \n",
       "3     A professor who teaches climate change classes...        environment   \n",
       "4     Looking around the United States, there is nev...           abortion   \n",
       "...                                                 ...                ...   \n",
       "1695  In every case legislators are being swarmed by...             gender   \n",
       "1696  Polls show the transgender ideology is deeply ...             gender   \n",
       "1697  Democrats and Republicans stood and applauded ...             gender   \n",
       "1698  As a self-described Democratic socialist, Sen....       middle-class   \n",
       "1699  During the segment, Colbert also bemoaned the ...  white-nationalism   \n",
       "\n",
       "      Label_bias                                  biased_words  \n",
       "0         Biased                         [belated, birtherism]  \n",
       "1     Non-biased                                      [bitter]  \n",
       "2         Biased                                      [crisis]  \n",
       "3     Non-biased                                  [legitimate]  \n",
       "4         Biased  [killing, never, developing, humans, enough]  \n",
       "...          ...                                           ...  \n",
       "1695      Biased       [deceit, hysteria, swarmed, right-wing]  \n",
       "1696      Biased                         [ideology, unpopular]  \n",
       "1697  Non-biased                                     [saluted]  \n",
       "1698  Non-biased                                   [outspoken]  \n",
       "1699  Non-biased                                    [bemoaned]  \n",
       "\n",
       "[1700 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Synsets\n",
    "Synsets are the meaning-distinguishable definitions of words or tokens. One application purpose is to extend the context to words with meaning equivalent words. For the given dataset, we would like to capture the synonyms to the biased words in the form of the lemmas to the associated synsets.\n",
    "### a) Find synsets\n",
    "Extract a list of the pairwise different biased words (column \"biased_words\") from the dataset and store them in a separate list \"b_words\" (not in the dataframe!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_l = [[\"a\", \"b\"], [\"c\"], [\"d\", \"e\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_l2 = [a for b in test_l for a in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_words = list(set([a for b in data.biased_words.to_list() for a in b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_words = [a for a in b_words if len(a)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exploit',\n",
       " 'conditions',\n",
       " 'socialists',\n",
       " 'diverting',\n",
       " 'ashamed',\n",
       " 'Democrats',\n",
       " 'penchant',\n",
       " 'Islamophobic',\n",
       " 'transgender',\n",
       " 'prioritizes']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Find synonyms\n",
    "For each of the words, determine all synsets and all lemmas belonging to the synsets. Store all pairwise different lemmas for all biased words in a list \"b_words_synonyms\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = []\n",
    "for word in b_words:\n",
    "    for syn in wn.synsets(word):\n",
    "         for lemma in syn.lemmas():\n",
    "                synonyms.extend([lemma.name()])\n",
    "\n",
    "b_words_synonyms = list(set(synonyms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyponyms (sub-term) and antonyms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'domestic_cat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"cat\")[0].hyponyms()[0].lemmas()[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "antonyms = []\n",
    "  \n",
    "for syn in wn.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['evil', 'evilness', 'bad', 'badness', 'bad', 'evil', 'ill']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3 Candidates for further biased words\n",
    "The synonyms for the biased words that you have just determined are a good starting point for manually determining additional biased words. Finally, create a list \"new_b_words\" in which you store all words of the list \"b_words_synonyms\" that are not contained in the original list of \"b_words\". For all 3 generated lists, display the number of words contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_b_words = [a for a in b_words_synonyms if a not in b_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2255\n",
      "10062\n",
      "8509\n"
     ]
    }
   ],
   "source": [
    "print(len(b_words))\n",
    "print(len(b_words_synonyms))\n",
    "print(len(new_b_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 GermaNet\n",
    "GermaNet is the version of Germanet developed at the University of Tübingen for relational synsemantic word networks in German. Although the basic functionalities are largely identical to Wordnet, they are called differently. Since you will be dealing more with German datasets from the ESUPOL project later in this course, GermaNet could be a useful tool for semantic analysis.\n",
    "\n",
    "### a: Install and import GermaNet\n",
    "GermaNet is not in the public domain; the TH Köln has been granted a license for use in the context of teaching and research. Therefore, use GermaNet only for assignments and projects within the scope of this course. \n",
    "Copy the provided folder \"germanetpy\" into your site-packages folder. \n",
    "Make sure that germanet is found properly. You can be sure and install the module again via pip:\n",
    "\n",
    "```python\n",
    "import sys\n",
    "!{sys.executable} -m pip install -U germanetpy\n",
    "```\n",
    "\n",
    "WordNet uses XML for relations and text files for frequencies, which must be stored in a specific location. Follow the instructions of the official API to set up GermaNet correctly:\n",
    "\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "from germanetpy.germanet import Germanet\n",
    "\n",
    "data_path = str(Path.home()) + \"/germanet/GN_V150/GN_V150_XML\"\n",
    "frequencylist_nouns = str(Path.home()) + \"/germanet/GN_V150/FreqLists/noun_freqs_decow14_16.txt\"\n",
    "germanet = Germanet(data_path)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: germanetpy in /home/fabian/.local/lib/python3.8/site-packages (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.14 in /home/fabian/anaconda3/lib/python3.8/site-packages (from germanetpy) (4.62.3)\n",
      "Requirement already satisfied, skipping upgrade: python-Levenshtein==0.12.0 in /home/fabian/.local/lib/python3.8/site-packages (from germanetpy) (0.12.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.18.1 in /home/fabian/anaconda3/lib/python3.8/site-packages (from germanetpy) (1.22.3)\n",
      "Requirement already satisfied, skipping upgrade: fastenum>=0.0.1 in /home/fabian/.local/lib/python3.8/site-packages (from germanetpy) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: lxml>=4.4.2 in /home/fabian/.local/lib/python3.8/site-packages (from germanetpy) (4.6.3)\n",
      "Requirement already satisfied, skipping upgrade: pytest>=5.3.2 in /home/fabian/.local/lib/python3.8/site-packages (from germanetpy) (7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/fabian/anaconda3/lib/python3.8/site-packages (from python-Levenshtein==0.12.0->germanetpy) (50.3.2)\n",
      "Requirement already satisfied, skipping upgrade: pluggy<2.0,>=0.12 in /home/fabian/.local/lib/python3.8/site-packages (from pytest>=5.3.2->germanetpy) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: iniconfig in /home/fabian/.local/lib/python3.8/site-packages (from pytest>=5.3.2->germanetpy) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: py>=1.8.2 in /home/fabian/.local/lib/python3.8/site-packages (from pytest>=5.3.2->germanetpy) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=19.2.0 in /home/fabian/anaconda3/lib/python3.8/site-packages (from pytest>=5.3.2->germanetpy) (21.4.0)\n",
      "Requirement already satisfied, skipping upgrade: tomli>=1.0.0 in /home/fabian/.local/lib/python3.8/site-packages (from pytest>=5.3.2->germanetpy) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /home/fabian/anaconda3/lib/python3.8/site-packages (from pytest>=5.3.2->germanetpy) (20.9)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /home/fabian/anaconda3/lib/python3.8/site-packages (from packaging->pytest>=5.3.2->germanetpy) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U germanetpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load GermaNet data...: 100%|█████████▉| 99.99999999999996/100 [00:09<00:00, 10.52it/s] \n",
      "Load Wictionary data...: 100%|██████████| 100.0/100 [00:00<00:00, 394.06it/s]            \n",
      "Load Ili records...: 100%|██████████| 100.0/100 [00:00<00:00, 140230.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from germanetpy.germanet import Germanet\n",
    "\n",
    "data_path = str(Path.home()) + \"/germanet/GN_V150/GN_V150_XML\"\n",
    "frequencylist_nouns = str(Path.home()) + \"/germanet/GN_V150/FreqLists/noun_freqs_decow14_16.txt\"\n",
    "germanet = Germanet(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b: Import data set\n",
    "Import the file \"single_term_suggestions.txt\" as a dataframe. The file contains a list of single-word query suggestions from the 2017 federal election dataset presented in the lecture. You can use the Pandas method \"read_csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ger = pd.read_csv(\"single_term_suggestions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=10d0e30c-5469-4fc1-b0f6-70fcfec6aef8 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('10d0e30c-5469-4fc1-b0f6-70fcfec6aef8').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suggestion_ger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aalten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aarburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaronn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>zwangsdienst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>zwangshypothek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>zweibruecken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>zwillinge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "      suggestion_ger\n",
       "0                 aa\n",
       "1               aach\n",
       "2             aalten\n",
       "3            aarburg\n",
       "4             aaronn\n",
       "...              ...\n",
       "3757    zwangsdienst\n",
       "3758  zwangshypothek\n",
       "3759    zweibruecken\n",
       "3760         zwickau\n",
       "3761       zwillinge\n",
       "\n",
       "[3762 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Using Germanet\n",
    "### a) Synsets\n",
    "Determine all synsets for each of the suggestions (i.e., each row of data) and store the list in a separate column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ger[\"synsets_ger\"] = data_ger.apply(lambda row: germanet.get_synsets_by_orthform(row[\"suggestion_ger\"], ignorecase = True), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Lexical units\n",
    "For each row, determine all lemmas (lexical units, i.e. lexunits) for all synsets and enter them as a list in a new column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synsets = germanet.get_synsets_by_orthform(\"Fußball\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexunit(id=l11339, orthform=Fußball, synset_id=s7944) \n",
      " Fußball\n"
     ]
    }
   ],
   "source": [
    "for a in fussball_synsets[1].lexunits:\n",
    "    print(a, \"\\n\",a.orthform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names_synsets(syns):\n",
    "    ret = []\n",
    "    try:\n",
    "        for syn in syns:\n",
    "            for lemma in syn.lexunits:\n",
    "                ret.extend(lemma.get_all_orthforms())\n",
    "    #print(ret)\n",
    "        return ret\n",
    "    except:\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ger[\"lexunits\"] = data_ger.apply(lambda row: get_names_synsets(row[\"synsets_ger\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=e0721fa9-d858-4ca7-ab53-c3e781d054f0 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('e0721fa9-d858-4ca7-ab53-c3e781d054f0').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suggestion_ger</th>\n",
       "      <th>synsets_ger</th>\n",
       "      <th>lexunits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>academy</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>accept</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>achtsamkeit</td>\n",
       "      <td>[Synset(id=s64491, lexunits=Achtsamkeit)]</td>\n",
       "      <td>[Achtsamkeit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>adel</td>\n",
       "      <td>[Synset(id=s24212, lexunits=Adelsgeschlecht, Adel), Synset(id=s32247, lexunits=Adelstitel, Adel, Adelsbezeichnung)]</td>\n",
       "      <td>[Adelsgeschlecht, Adel, Adelstitel, Adel, Adelsbezeichnung]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>adidas</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>afd</td>\n",
       "      <td>[Synset(id=s142253, lexunits=AfD, Alternative für Deutschland)]</td>\n",
       "      <td>[AfD, Alternative für Deutschland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>affair</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>affeln</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>affing</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>[Synset(id=s44583, lexunits=Afghanistan)]</td>\n",
       "      <td>[Afghanistan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "     suggestion_ger                                        synsets_ger  \\\n",
       "23          academy                                                 []   \n",
       "24           accept                                                 []   \n",
       "25      achtsamkeit          [Synset(id=s64491, lexunits=Achtsamkeit)]   \n",
       "26             adel  [Synset(id=s24212, lexunits=Adelsgeschlecht, A...   \n",
       "27           adidas                                                 []   \n",
       "28       adipositas  [Synset(id=s26923, lexunits=Esssucht, Fettsuch...   \n",
       "29        adlershof            [Synset(id=s63203, lexunits=Adlershof)]   \n",
       "30            adobe                [Synset(id=s73648, lexunits=Adobe)]   \n",
       "31         adoption             [Synset(id=s18550, lexunits=Adoption)]   \n",
       "32          adresse  [Synset(id=s32396, lexunits=Anschrift, Adresse...   \n",
       "33  adventskalender  [Synset(id=s11312, lexunits=Adventskalender, W...   \n",
       "34         advocaat                                                 []   \n",
       "35         aegypten                                                 []   \n",
       "36     aerztekammer                                                 []   \n",
       "37          aerztin                                                 []   \n",
       "38              afa                                                 []   \n",
       "39              afd  [Synset(id=s142253, lexunits=AfD, Alternative ...   \n",
       "40           affair                                                 []   \n",
       "41           affeln                                                 []   \n",
       "42           affing                                                 []   \n",
       "43      afghanistan          [Synset(id=s44583, lexunits=Afghanistan)]   \n",
       "\n",
       "                                             lexunits  \n",
       "23                                                 []  \n",
       "24                                                 []  \n",
       "25                                      [Achtsamkeit]  \n",
       "26  [Adelsgeschlecht, Adel, Adelstitel, Adel, Adel...  \n",
       "27                                                 []  \n",
       "28  [Eßsucht, Ess-Sucht, Esssucht, Fettsucht, Adip...  \n",
       "29                                        [Adlershof]  \n",
       "30                                            [Adobe]  \n",
       "31                                         [Adoption]  \n",
       "32  [Anschrift, Adresse, Wohnsitz, Adresse, Adress...  \n",
       "33              [Adventskalender, Weihnachtskalender]  \n",
       "34                                                 []  \n",
       "35                                                 []  \n",
       "36                                                 []  \n",
       "37                                                 []  \n",
       "38                                                 []  \n",
       "39                 [AfD, Alternative für Deutschland]  \n",
       "40                                                 []  \n",
       "41                                                 []  \n",
       "42                                                 []  \n",
       "43                                      [Afghanistan]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ger[23:44]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Hypernyms\n",
    "Semantic networks such as Germanet describe actual relationships between synsets. Hypernyms (supertypes) and hyponyms (subtypes) can be useful for classifying terms.\n",
    "Determine all hypernyms for all synsets of each suggestion and store their synsets in a column \"hypernyms\". Then determine the lemmas of these hypernyms and store them in a separate column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypernyms_from_list_of_synsets(list_syns):\n",
    "    for syn in list_syns:\n",
    "        return syn.direct_hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ger[\"hypernyms\"] = data_ger.apply(lambda row: get_hypernyms_from_list_of_synsets(row[\"synsets_ger\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ger[\"lexunits_hypernyms\"] = data_ger.apply(lambda row: get_names_synsets(row[\"hypernyms\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Hyponyms\n",
    "Proceed as in c, but this time determine the hyponyms of the suggestions and their lemmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyponyms_from_list_of_synsets(list_syns):\n",
    "    for syn in list_syns:\n",
    "        return syn.direct_hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ger[\"hyponyms\"] = data_ger.apply(lambda row: get_hyponyms_from_list_of_synsets(row[\"synsets_ger\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ger[\"lexunits_hyponyms\"] = data_ger.apply(lambda row: get_names_synsets(row[\"hyponyms\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=165b29d7-a9f2-424c-9446-556c4d361719 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('165b29d7-a9f2-424c-9446-556c4d361719').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suggestion_ger</th>\n",
       "      <th>lexunits_hypernyms</th>\n",
       "      <th>lexunits_hyponyms</th>\n",
       "      <th>lexunits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>[Fluggesellschaft, Luftfahrtgesellschaft, Fluglinie, Airline]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[American Airlines, AA, Kot, Scheiße, Exkrement, Stuhl, Kacke, Kaka, Aa, Stuhlgang]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aach</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aalten</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aarburg</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaronn</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>zwangsdienst</td>\n",
       "      <td>[Dienst]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Zwangsdienst]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>zwangshypothek</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>zweibruecken</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>zwickau</td>\n",
       "      <td>[Stadt]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Zwickau]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>zwillinge</td>\n",
       "      <td>[Sternzeichen, Sternbild, Tierkreiszeichen, Haus]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Zwillinge]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "      suggestion_ger                                 lexunits_hypernyms  \\\n",
       "0                 aa  [Fluggesellschaft, Luftfahrtgesellschaft, Flug...   \n",
       "1               aach                                                 []   \n",
       "2             aalten                                                 []   \n",
       "3            aarburg                                                 []   \n",
       "4             aaronn                                                 []   \n",
       "...              ...                                                ...   \n",
       "3757    zwangsdienst                                           [Dienst]   \n",
       "3758  zwangshypothek                                                 []   \n",
       "3759    zweibruecken                                                 []   \n",
       "3760         zwickau                                            [Stadt]   \n",
       "3761       zwillinge  [Sternzeichen, Sternbild, Tierkreiszeichen, Haus]   \n",
       "\n",
       "     lexunits_hyponyms                                           lexunits  \n",
       "0                   []  [American Airlines, AA, Kot, Scheiße, Exkremen...  \n",
       "1                   []                                                 []  \n",
       "2                   []                                                 []  \n",
       "3                   []                                                 []  \n",
       "4                   []                                                 []  \n",
       "...                ...                                                ...  \n",
       "3757                []                                     [Zwangsdienst]  \n",
       "3758                []                                                 []  \n",
       "3759                []                                                 []  \n",
       "3760                []                                          [Zwickau]  \n",
       "3761                []                                        [Zwillinge]  \n",
       "\n",
       "[3762 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ger[[\"suggestion_ger\",\"lexunits_hypernyms\", \"lexunits_hyponyms\", \"lexunits\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of all pairwise different hypernyms, hyponyms and lemmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexunits_hypernyms = list(set([a for b in data_ger.lexunits_hypernyms for a in b]))\n",
    "lexunits_hyponyms = list(set([a for b in data_ger.lexunits_hyponyms for a in b]))\n",
    "lexunits = list(set([a for b in data_ger.lexunits for a in b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026\n",
      "12543\n"
     ]
    }
   ],
   "source": [
    "print(len(lexunits_hypernyms))\n",
    "print(len(lexunits_hyponyms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Classification tags with synsets\n",
    "Synsemantic networks can be used, for example, to classify terms. \n",
    "Use the identified hypernyms to find all cities in the dataset. In a \"location\" column, classify all cities, countries and places as \"True\" and all other suggestions as \"False\". Display a sub-dataframe of all locations in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_word_in_list(liste, words):\n",
    "    for word in words:\n",
    "        if word in liste:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ger[\"city\"] = data_ger.apply(lambda row: is_word_in_list(row[\"lexunits_hypernyms\"], [\"Land\", \"Dorf\", \"Stadt\", \"Ort\", \"Platz\", \"Staat\", \"Bundesland\" ]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=01b8803f-0c68-4316-b2a2-adfd78c707ee style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('01b8803f-0c68-4316-b2a2-adfd78c707ee').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suggestion_ger</th>\n",
       "      <th>synsets_ger</th>\n",
       "      <th>lexunits</th>\n",
       "      <th>hypernyms</th>\n",
       "      <th>lexunits_hypernyms</th>\n",
       "      <th>hyponyms</th>\n",
       "      <th>lexunits_hyponyms</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>[Synset(id=s44583, lexunits=Afghanistan)]</td>\n",
       "      <td>[Afghanistan]</td>\n",
       "      <td>{Synset(id=s44177, lexunits=Land, Staat)}</td>\n",
       "      <td>[Land, Staat]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>albanien</td>\n",
       "      <td>[Synset(id=s44497, lexunits=Albanien)]</td>\n",
       "      <td>[Albanien]</td>\n",
       "      <td>{Synset(id=s44177, lexunits=Land, Staat)}</td>\n",
       "      <td>[Land, Staat]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>aleppo</td>\n",
       "      <td>[Synset(id=s73659, lexunits=Aleppo)]</td>\n",
       "      <td>[Aleppo]</td>\n",
       "      <td>{Synset(id=s43645, lexunits=Stadt)}</td>\n",
       "      <td>[Stadt]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>altenburg</td>\n",
       "      <td>[Synset(id=s73693, lexunits=Altenburg)]</td>\n",
       "      <td>[Altenburg]</td>\n",
       "      <td>{Synset(id=s43645, lexunits=Stadt)}</td>\n",
       "      <td>[Stadt]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>amorbach</td>\n",
       "      <td>[Synset(id=s44036, lexunits=Amorbach)]</td>\n",
       "      <td>[Amorbach]</td>\n",
       "      <td>{Synset(id=s43645, lexunits=Stadt)}</td>\n",
       "      <td>[Stadt]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3666</th>\n",
       "      <td>wittenberg</td>\n",
       "      <td>[Synset(id=s44111, lexunits=Wittenberg)]</td>\n",
       "      <td>[Wittenberg]</td>\n",
       "      <td>{Synset(id=s43645, lexunits=Stadt)}</td>\n",
       "      <td>[Stadt]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3691</th>\n",
       "      <td>worms</td>\n",
       "      <td>[Synset(id=s44019, lexunits=Worms)]</td>\n",
       "      <td>[Worms]</td>\n",
       "      <td>{Synset(id=s43645, lexunits=Stadt)}</td>\n",
       "      <td>[Stadt]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3702</th>\n",
       "      <td>wuppertal</td>\n",
       "      <td>[Synset(id=s44061, lexunits=Wuppertal)]</td>\n",
       "      <td>[Wuppertal]</td>\n",
       "      <td>{Synset(id=s43645, lexunits=Stadt)}</td>\n",
       "      <td>[Stadt]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>xanten</td>\n",
       "      <td>[Synset(id=s44082, lexunits=Xanten)]</td>\n",
       "      <td>[Xanten]</td>\n",
       "      <td>{Synset(id=s43645, lexunits=Stadt)}</td>\n",
       "      <td>[Stadt]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>zwickau</td>\n",
       "      <td>[Synset(id=s44112, lexunits=Zwickau)]</td>\n",
       "      <td>[Zwickau]</td>\n",
       "      <td>{Synset(id=s43645, lexunits=Stadt)}</td>\n",
       "      <td>[Stadt]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "     suggestion_ger                                synsets_ger       lexunits  \\\n",
       "43      afghanistan  [Synset(id=s44583, lexunits=Afghanistan)]  [Afghanistan]   \n",
       "64         albanien     [Synset(id=s44497, lexunits=Albanien)]     [Albanien]   \n",
       "69           aleppo       [Synset(id=s73659, lexunits=Aleppo)]       [Aleppo]   \n",
       "99        altenburg    [Synset(id=s73693, lexunits=Altenburg)]    [Altenburg]   \n",
       "121        amorbach     [Synset(id=s44036, lexunits=Amorbach)]     [Amorbach]   \n",
       "...             ...                                        ...            ...   \n",
       "3666     wittenberg   [Synset(id=s44111, lexunits=Wittenberg)]   [Wittenberg]   \n",
       "3691          worms        [Synset(id=s44019, lexunits=Worms)]        [Worms]   \n",
       "3702      wuppertal    [Synset(id=s44061, lexunits=Wuppertal)]    [Wuppertal]   \n",
       "3707         xanten       [Synset(id=s44082, lexunits=Xanten)]       [Xanten]   \n",
       "3760        zwickau      [Synset(id=s44112, lexunits=Zwickau)]      [Zwickau]   \n",
       "\n",
       "                                      hypernyms lexunits_hypernyms hyponyms  \\\n",
       "43    {Synset(id=s44177, lexunits=Land, Staat)}      [Land, Staat]       {}   \n",
       "64    {Synset(id=s44177, lexunits=Land, Staat)}      [Land, Staat]       {}   \n",
       "69          {Synset(id=s43645, lexunits=Stadt)}            [Stadt]       {}   \n",
       "99          {Synset(id=s43645, lexunits=Stadt)}            [Stadt]       {}   \n",
       "121         {Synset(id=s43645, lexunits=Stadt)}            [Stadt]       {}   \n",
       "...                                         ...                ...      ...   \n",
       "3666        {Synset(id=s43645, lexunits=Stadt)}            [Stadt]       {}   \n",
       "3691        {Synset(id=s43645, lexunits=Stadt)}            [Stadt]       {}   \n",
       "3702        {Synset(id=s43645, lexunits=Stadt)}            [Stadt]       {}   \n",
       "3707        {Synset(id=s43645, lexunits=Stadt)}            [Stadt]       {}   \n",
       "3760        {Synset(id=s43645, lexunits=Stadt)}            [Stadt]       {}   \n",
       "\n",
       "     lexunits_hyponyms  city  \n",
       "43                  []  True  \n",
       "64                  []  True  \n",
       "69                  []  True  \n",
       "99                  []  True  \n",
       "121                 []  True  \n",
       "...                ...   ...  \n",
       "3666                []  True  \n",
       "3691                []  True  \n",
       "3702                []  True  \n",
       "3707                []  True  \n",
       "3760                []  True  \n",
       "\n",
       "[196 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ger.loc[(data_ger[\"city\"]==True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS TASK: Semantic Similarity and Relatedness\n",
    "The relational structure of synsets can be used to infer the similarity or relatedness of two terms of the same word type. In turn, the similarity can be used, for example, to eliminate ambiguity. In the case of the dataset, the terms form search suggestions to person-related searches in search engines, which are based on the names of politicians as search terms. Thus, the term \"abort\" was suggested as a search suggestion for at least one politician's name. To identify the relevant synset from the suggestions, the similarity to the synset \"politician\" ( synset(id=s34818, lexunits=politician, politician) ) can be determined. \n",
    "\n",
    "Proceed as explained in the official GermaNet tutorial (https://github.com/Germanet-sfs/germanetTutorials/tree/master/pythonAPI) to calculate the similarity to the politician synset for all synsets of all suggestions, respectively, and store the synset with the highest similarity in a \"best_syn\" column. Use either Path- or IC- based similarity or run both separately. Finally, export a sub-dataframe containing only those rows whose suggestion has at least 2 synsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ger[\"synsets_check\"] = data_ger.apply(lambda row: len(row[\"synsets_ger\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=b8a041db-d02d-4aa0-bef3-6638a851a68c style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('b8a041db-d02d-4aa0-bef3-6638a851a68c').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suggestion_ger</th>\n",
       "      <th>synsets_ger</th>\n",
       "      <th>lexunits</th>\n",
       "      <th>hypernyms</th>\n",
       "      <th>lexunits_hypernyms</th>\n",
       "      <th>hyponyms</th>\n",
       "      <th>lexunits_hyponyms</th>\n",
       "      <th>city</th>\n",
       "      <th>synsets_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>[Synset(id=s23506, lexunits=American Airlines, AA), Synset(id=s26358, lexunits=Kot, Scheiße, Exkrement, Stuhl, Kacke, Kaka, Aa, Stuhlgang)]</td>\n",
       "      <td>[American Airlines, AA, Kot, Scheiße, Exkrement, Stuhl, Kacke, Kaka, Aa, Stuhlgang]</td>\n",
       "      <td>{Synset(id=s23493, lexunits=Fluggesellschaft, Luftfahrtgesellschaft, Fluglinie, Airline)}</td>\n",
       "      <td>[Fluggesellschaft, Luftfahrtgesellschaft, Fluglinie, Airline]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aach</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aalten</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aarburg</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaronn</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>zwangsdienst</td>\n",
       "      <td>[Synset(id=s131522, lexunits=Zwangsdienst)]</td>\n",
       "      <td>[Zwangsdienst]</td>\n",
       "      <td>{Synset(id=s19797, lexunits=Dienst)}</td>\n",
       "      <td>[Dienst]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>zwangshypothek</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>zweibruecken</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>zwickau</td>\n",
       "      <td>[Synset(id=s44112, lexunits=Zwickau)]</td>\n",
       "      <td>[Zwickau]</td>\n",
       "      <td>{Synset(id=s43645, lexunits=Stadt)}</td>\n",
       "      <td>[Stadt]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>zwillinge</td>\n",
       "      <td>[Synset(id=s29525, lexunits=Zwillinge)]</td>\n",
       "      <td>[Zwillinge]</td>\n",
       "      <td>{Synset(id=s29522, lexunits=Sternzeichen, Sternbild, Tierkreiszeichen, Haus)}</td>\n",
       "      <td>[Sternzeichen, Sternbild, Tierkreiszeichen, Haus]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "      suggestion_ger                                        synsets_ger  \\\n",
       "0                 aa  [Synset(id=s23506, lexunits=American Airlines,...   \n",
       "1               aach                                                 []   \n",
       "2             aalten                                                 []   \n",
       "3            aarburg                                                 []   \n",
       "4             aaronn                                                 []   \n",
       "...              ...                                                ...   \n",
       "3757    zwangsdienst        [Synset(id=s131522, lexunits=Zwangsdienst)]   \n",
       "3758  zwangshypothek                                                 []   \n",
       "3759    zweibruecken                                                 []   \n",
       "3760         zwickau              [Synset(id=s44112, lexunits=Zwickau)]   \n",
       "3761       zwillinge            [Synset(id=s29525, lexunits=Zwillinge)]   \n",
       "\n",
       "                                               lexunits  \\\n",
       "0     [American Airlines, AA, Kot, Scheiße, Exkremen...   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "3757                                     [Zwangsdienst]   \n",
       "3758                                                 []   \n",
       "3759                                                 []   \n",
       "3760                                          [Zwickau]   \n",
       "3761                                        [Zwillinge]   \n",
       "\n",
       "                                              hypernyms  \\\n",
       "0     {Synset(id=s23493, lexunits=Fluggesellschaft, ...   \n",
       "1                                                  None   \n",
       "2                                                  None   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "3757               {Synset(id=s19797, lexunits=Dienst)}   \n",
       "3758                                               None   \n",
       "3759                                               None   \n",
       "3760                {Synset(id=s43645, lexunits=Stadt)}   \n",
       "3761  {Synset(id=s29522, lexunits=Sternzeichen, Ster...   \n",
       "\n",
       "                                     lexunits_hypernyms hyponyms  \\\n",
       "0     [Fluggesellschaft, Luftfahrtgesellschaft, Flug...       {}   \n",
       "1                                                    []     None   \n",
       "2                                                    []     None   \n",
       "3                                                    []     None   \n",
       "4                                                    []     None   \n",
       "...                                                 ...      ...   \n",
       "3757                                           [Dienst]       {}   \n",
       "3758                                                 []     None   \n",
       "3759                                                 []     None   \n",
       "3760                                            [Stadt]       {}   \n",
       "3761  [Sternzeichen, Sternbild, Tierkreiszeichen, Haus]       {}   \n",
       "\n",
       "     lexunits_hyponyms   city  synsets_check  \n",
       "0                   []  False              2  \n",
       "1                   []  False              0  \n",
       "2                   []  False              0  \n",
       "3                   []  False              0  \n",
       "4                   []  False              0  \n",
       "...                ...    ...            ...  \n",
       "3757                []  False              1  \n",
       "3758                []  False              0  \n",
       "3759                []  False              0  \n",
       "3760                []   True              1  \n",
       "3761                []  False              1  \n",
       "\n",
       "[3762 rows x 9 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bonus = data_ger.loc[(data_ger[\"synsets_check\"]>1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=63608748-8263-4300-85bc-ec341543f0d9 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('63608748-8263-4300-85bc-ec341543f0d9').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suggestion_ger</th>\n",
       "      <th>synsets_ger</th>\n",
       "      <th>lexunits</th>\n",
       "      <th>hypernyms</th>\n",
       "      <th>lexunits_hypernyms</th>\n",
       "      <th>hyponyms</th>\n",
       "      <th>lexunits_hyponyms</th>\n",
       "      <th>city</th>\n",
       "      <th>synsets_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>[Synset(id=s23506, lexunits=American Airlines, AA), Synset(id=s26358, lexunits=Kot, Scheiße, Exkrement, Stuhl, Kacke, Kaka, Aa, Stuhlgang)]</td>\n",
       "      <td>[American Airlines, AA, Kot, Scheiße, Exkrement, Stuhl, Kacke, Kaka, Aa, Stuhlgang]</td>\n",
       "      <td>{Synset(id=s23493, lexunits=Fluggesellschaft, Luftfahrtgesellschaft, Fluglinie, Airline)}</td>\n",
       "      <td>[Fluggesellschaft, Luftfahrtgesellschaft, Fluglinie, Airline]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abbruch</td>\n",
       "      <td>[Synset(id=s22422, lexunits=Abbruch, Beendigung, Beenden, Aufhören, Beendung), Synset(id=s106337, lexunits=Abbruch), Synset(id=s106285, lexunits=Abbruch), Synset(id=s106286, lexunits=Abbruch), Synset(id=s21303, lexunits=Abriss, Abbruch, Niederreißung)]</td>\n",
       "      <td>[Abbruch, Beendigung, Beenden, Aufhören, Beendung, Abbruch, Abbruch, Abbruch, Abriß, Abriss, Abbruch, Niederreißung]</td>\n",
       "      <td>{Synset(id=s21961, lexunits=Veränderung, Änderung)}</td>\n",
       "      <td>[Veränderung, Änderung]</td>\n",
       "      <td>{Synset(id=s121482, lexunits=Schulabbruch), Synset(id=s22427, lexunits=Ausschaltung, Ausschalten), Synset(id=s113518, lexunits=Bauabbruch), Synset(id=s72930, lexunits=Ablauf), Synset(id=s117289, lexunits=Startabbruch), Synset(id=s22429, lexunits=Abkehr, Abwendung), Synset(id=s100335, lexunits=Vertragsbeendigung), Synset(id=s123548, lexunits=Verbindungsabbruch), Synset(id=s22430, lexunits=Einstellung), Synset(id=s22517, lexunits=Vollendung), Synset(id=s22518, lexunits=Aufkündigung, Kündigung, Vertragsauflösung, Vertragskündigung, Vertragsaufhebung), Synset(id=s22432, lexunits=Schließung), Synset(id=s140469, lexunits=Fastenbrechen), Synset(id=s149250, lexunits=Aufenthaltsbeendigung), Synset(id=s22433, lexunits=Auflösung), Synset(id=s147580, lexunits=Kontaktabbruch), Synset(id=s92201, lexunits=Ausblendung), Synset(id=s101983, lexunits=Spielabbruch), Synset(id=s22435, lexunits=Niederlegung), Synset(id=s22436, lexunits=Entlassen, Entlassung), Synset(id=s106452, lexunits=Aufhebung), Synset(id=s112714, lexunits=Studienabbruch), Synset(id=s68923, lexunits=Endanflug), Synset(id=s22439, lexunits=Ableistung), Synset(id=s22423, lexunits=Niederschlagung), Synset(id=s22424, lexunits=Niederschlagung), Synset(id=s51777, lexunits=Ausstieg, Ausstiegsphase), Synset(id=s22425, lexunits=Abschaffung, Abschaffen)}</td>\n",
       "      <td>[Schulabbruch, Ausschaltung, Ausschalten, Bauabbruch, Ablauf, Startabbruch, Abkehr, Abwendung, Vertragsbeendigung, Verbindungsabbruch, Einstellung, Vollendung, Aufkündigung, Kündigung, Vertragsauflösung, Vertragskündigung, Vertragsaufhebung, Schließung, Fastenbrechen, Aufenthaltsbeendigung, Auflösung, Kontaktabbruch, Ausblendung, Spielabbruch, Niederlegung, Entlassen, Entlassung, Aufhebung, Studienabbruch, Endanflug, Ableistung, Niederschlagung, Niederschlagung, Ausstieg, Ausstiegsphase, Abschaffung, Abschaffen]</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>abnehmen</td>\n",
       "      <td>[Synset(id=s53836, lexunits=abnehmen), Synset(id=s53908, lexunits=abchecken, abnehmen, begutachten, checken), Synset(id=s53807, lexunits=abnehmen), Synset(id=s56878, lexunits=abnehmen, herunternehmen, runternehmen), Synset(id=s60512, lexunits=abnehmen), Synset(id=s54392, lexunits=abnehmen), Synset(id=s54723, lexunits=abnehmen, abkaufen), Synset(id=s60521, lexunits=abnehmen), Synset(id=s52508, lexunits=wegnehmen, abnehmen, fortnehmen), Synset(id=s59787, lexunits=abnehmen)]</td>\n",
       "      <td>[abnehmen, abchecken, abnehmen, begutachten, checken, abnehmen, abnehmen, herunternehmen, runternehmen, abnehmen, abnehmen, abnehmen, abkaufen, abnehmen, wegnehmen, abnehmen, fortnehmen, abnehmen]</td>\n",
       "      <td>{Synset(id=s53835, lexunits=helfen)}</td>\n",
       "      <td>[helfen]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>abschied</td>\n",
       "      <td>[Synset(id=s105682, lexunits=Abschied), Synset(id=s17481, lexunits=Abschied, Lebewohl, Verabschiedung)]</td>\n",
       "      <td>[Abschied, Abschied, Lebewohl, Verabschiedung]</td>\n",
       "      <td>{Synset(id=s22436, lexunits=Entlassen, Entlassung)}</td>\n",
       "      <td>[Entlassen, Entlassung]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>adel</td>\n",
       "      <td>[Synset(id=s24212, lexunits=Adelsgeschlecht, Adel), Synset(id=s32247, lexunits=Adelstitel, Adel, Adelsbezeichnung)]</td>\n",
       "      <td>[Adelsgeschlecht, Adel, Adelstitel, Adel, Adelsbezeichnung]</td>\n",
       "      <td>{Synset(id=s24202, lexunits=Haus, Geschlecht, Dynastie, Familiendynastie, Familienclan)}</td>\n",
       "      <td>[Haus, Geschlecht, Dynastie, Familiendynastie, Familienclan]</td>\n",
       "      <td>{Synset(id=s93207, lexunits=Dienstadel), Synset(id=s136589, lexunits=Kriegeradel), Synset(id=s24215, lexunits=Hochadel), Synset(id=s111596, lexunits=Kleinadel), Synset(id=s65784, lexunits=Edelleute), Synset(id=s65171, lexunits=Ortsadel), Synset(id=s92515, lexunits=Gentry), Synset(id=s63065, lexunits=Uradel), Synset(id=s24216, lexunits=Bauernadel, Landadel), Synset(id=s87133, lexunits=Hofadel), Synset(id=s101528, lexunits=Erbadel), Synset(id=s122751, lexunits=Feudaladel), Synset(id=s24214, lexunits=Noblesse), Synset(id=s102967, lexunits=Reichsadel), Synset(id=s24217, lexunits=Stadtadel), Synset(id=s76879, lexunits=Amtsadel)}</td>\n",
       "      <td>[Dienstadel, Kriegeradel, Hochadel, Kleinadel, Edelleute, Ortsadel, Gentry, Uradel, Bauernadel, Landadel, Hofadel, Erbadel, Feudaladel, Noblesse, Reichsadel, Stadtadel, Amtsadel]</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>zirkus</td>\n",
       "      <td>[Synset(id=s108415, lexunits=Zirkus), Synset(id=s73248, lexunits=Zirkus, Zirkusunternehmen), Synset(id=s17960, lexunits=Zirkus), Synset(id=s14333, lexunits=Rabatz, Radau, Trubel, Theater, Zirkus)]</td>\n",
       "      <td>[Circus, Zirkus, Circus, Zirkus, Zirkusunternehmen, Circus, Zirkus, Rabatz, Radau, Trubel, Theater, Zirkus]</td>\n",
       "      <td>{Synset(id=s42745, lexunits=Arena, Stadion)}</td>\n",
       "      <td>[Arena, Stadion]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>zitat</td>\n",
       "      <td>[Synset(id=s32274, lexunits=Zitat), Synset(id=s32501, lexunits=Zitat)]</td>\n",
       "      <td>[Zitat, Zitat]</td>\n",
       "      <td>{Synset(id=s32267, lexunits=Redewendung, Idiom, Redensart, Wendung)}</td>\n",
       "      <td>[Redewendung, Idiom, Redensart, Wendung]</td>\n",
       "      <td>{Synset(id=s137738, lexunits=Selbstzitat)}</td>\n",
       "      <td>[Selbstzitat]</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>zug</td>\n",
       "      <td>[Synset(id=s40992, lexunits=Zugkraft, Zug), Synset(id=s41350, lexunits=Luftzug, Zug, Luft), Synset(id=s17675, lexunits=Zug), Synset(id=s8724, lexunits=Eisenbahn, Eisenbahnzug, Zug, Bahn), Synset(id=s14348, lexunits=Gesichtszug, Zug), Synset(id=s76189, lexunits=Zug), Synset(id=s21974, lexunits=Ziehen, Zug), Synset(id=s76183, lexunits=Zug), Synset(id=s109599, lexunits=Zug), Synset(id=s76184, lexunits=Zug), Synset(id=s14044, lexunits=Charaktereigenschaft, Charakterzug, Zug, Wesenszug, Charaktermerkmal), Synset(id=s8959, lexunits=Lastzug, Zug), Synset(id=s76185, lexunits=Zug), Synset(id=s44336, lexunits=Zug)]</td>\n",
       "      <td>[Zugkraft, Zug, Luftzug, Zug, Luft, Zug, Eisenbahn, Eisenbahnzug, Zug, Bahn, Gesichtszug, Zug, Zug, Ziehen, Zug, Zug, Zug, Zug, Charaktereigenschaft, Charakterzug, Zug, Wesenszug, Charaktermerkmal, Lastzug, Zug, Zug, Zug]</td>\n",
       "      <td>{Synset(id=s40976, lexunits=Kraft)}</td>\n",
       "      <td>[Kraft]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>zukunft</td>\n",
       "      <td>[Synset(id=s51054, lexunits=Zukunft, Vorzeitigkeit, Hinkunft), Synset(id=s64962, lexunits=Futur, Zukunft, Futurum)]</td>\n",
       "      <td>[Zukunft, Vorzeitigkeit, Hinkunft, Futur, Zukunft, Futurum]</td>\n",
       "      <td>{Synset(id=s51051, lexunits=Zeitstufe)}</td>\n",
       "      <td>[Zeitstufe]</td>\n",
       "      <td>{Synset(id=s139797, lexunits=Energiezukunft), Synset(id=s22920, lexunits=Nachwelt), Synset(id=s100061, lexunits=Vorweg)}</td>\n",
       "      <td>[Energiezukunft, Nachwelt, Vorweg]</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>zusammenbruch</td>\n",
       "      <td>[Synset(id=s17119, lexunits=Zusammenbruch, Crash), Synset(id=s17538, lexunits=Kollaps, Zusammenbruch)]</td>\n",
       "      <td>[Zusammenbruch, Crash, Kollaps, Zusammenbruch]</td>\n",
       "      <td>{Synset(id=s21256, lexunits=Zerstörung, Destruktion)}</td>\n",
       "      <td>[Zerstörung, Destruktion]</td>\n",
       "      <td>{Synset(id=s69105, lexunits=Börsencrash)}</td>\n",
       "      <td>[Börsencrash]</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "     suggestion_ger                                        synsets_ger  \\\n",
       "0                aa  [Synset(id=s23506, lexunits=American Airlines,...   \n",
       "6           abbruch  [Synset(id=s22422, lexunits=Abbruch, Beendigun...   \n",
       "15         abnehmen  [Synset(id=s53836, lexunits=abnehmen), Synset(...   \n",
       "18         abschied  [Synset(id=s105682, lexunits=Abschied), Synset...   \n",
       "26             adel  [Synset(id=s24212, lexunits=Adelsgeschlecht, A...   \n",
       "...             ...                                                ...   \n",
       "3741         zirkus  [Synset(id=s108415, lexunits=Zirkus), Synset(i...   \n",
       "3742          zitat  [Synset(id=s32274, lexunits=Zitat), Synset(id=...   \n",
       "3752            zug  [Synset(id=s40992, lexunits=Zugkraft, Zug), Sy...   \n",
       "3753        zukunft  [Synset(id=s51054, lexunits=Zukunft, Vorzeitig...   \n",
       "3755  zusammenbruch  [Synset(id=s17119, lexunits=Zusammenbruch, Cra...   \n",
       "\n",
       "                                               lexunits  \\\n",
       "0     [American Airlines, AA, Kot, Scheiße, Exkremen...   \n",
       "6     [Abbruch, Beendigung, Beenden, Aufhören, Beend...   \n",
       "15    [abnehmen, abchecken, abnehmen, begutachten, c...   \n",
       "18       [Abschied, Abschied, Lebewohl, Verabschiedung]   \n",
       "26    [Adelsgeschlecht, Adel, Adelstitel, Adel, Adel...   \n",
       "...                                                 ...   \n",
       "3741  [Circus, Zirkus, Circus, Zirkus, Zirkusunterne...   \n",
       "3742                                     [Zitat, Zitat]   \n",
       "3752  [Zugkraft, Zug, Luftzug, Zug, Luft, Zug, Eisen...   \n",
       "3753  [Zukunft, Vorzeitigkeit, Hinkunft, Futur, Zuku...   \n",
       "3755     [Zusammenbruch, Crash, Kollaps, Zusammenbruch]   \n",
       "\n",
       "                                              hypernyms  \\\n",
       "0     {Synset(id=s23493, lexunits=Fluggesellschaft, ...   \n",
       "6     {Synset(id=s21961, lexunits=Veränderung, Änder...   \n",
       "15                 {Synset(id=s53835, lexunits=helfen)}   \n",
       "18    {Synset(id=s22436, lexunits=Entlassen, Entlass...   \n",
       "26    {Synset(id=s24202, lexunits=Haus, Geschlecht, ...   \n",
       "...                                                 ...   \n",
       "3741       {Synset(id=s42745, lexunits=Arena, Stadion)}   \n",
       "3742  {Synset(id=s32267, lexunits=Redewendung, Idiom...   \n",
       "3752                {Synset(id=s40976, lexunits=Kraft)}   \n",
       "3753            {Synset(id=s51051, lexunits=Zeitstufe)}   \n",
       "3755  {Synset(id=s21256, lexunits=Zerstörung, Destru...   \n",
       "\n",
       "                                     lexunits_hypernyms  \\\n",
       "0     [Fluggesellschaft, Luftfahrtgesellschaft, Flug...   \n",
       "6                               [Veränderung, Änderung]   \n",
       "15                                             [helfen]   \n",
       "18                              [Entlassen, Entlassung]   \n",
       "26    [Haus, Geschlecht, Dynastie, Familiendynastie,...   \n",
       "...                                                 ...   \n",
       "3741                                   [Arena, Stadion]   \n",
       "3742           [Redewendung, Idiom, Redensart, Wendung]   \n",
       "3752                                            [Kraft]   \n",
       "3753                                        [Zeitstufe]   \n",
       "3755                          [Zerstörung, Destruktion]   \n",
       "\n",
       "                                               hyponyms  \\\n",
       "0                                                    {}   \n",
       "6     {Synset(id=s121482, lexunits=Schulabbruch), Sy...   \n",
       "15                                                   {}   \n",
       "18                                                   {}   \n",
       "26    {Synset(id=s93207, lexunits=Dienstadel), Synse...   \n",
       "...                                                 ...   \n",
       "3741                                                 {}   \n",
       "3742         {Synset(id=s137738, lexunits=Selbstzitat)}   \n",
       "3752                                                 {}   \n",
       "3753  {Synset(id=s139797, lexunits=Energiezukunft), ...   \n",
       "3755          {Synset(id=s69105, lexunits=Börsencrash)}   \n",
       "\n",
       "                                      lexunits_hyponyms   city  synsets_check  \n",
       "0                                                    []  False              2  \n",
       "6     [Schulabbruch, Ausschaltung, Ausschalten, Baua...  False              5  \n",
       "15                                                   []  False             10  \n",
       "18                                                   []  False              2  \n",
       "26    [Dienstadel, Kriegeradel, Hochadel, Kleinadel,...  False              2  \n",
       "...                                                 ...    ...            ...  \n",
       "3741                                                 []  False              4  \n",
       "3742                                      [Selbstzitat]  False              2  \n",
       "3752                                                 []  False             14  \n",
       "3753                 [Energiezukunft, Nachwelt, Vorweg]  False              2  \n",
       "3755                                      [Börsencrash]  False              2  \n",
       "\n",
       "[451 rows x 9 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file /home/fabian/germanet/GN_V150/FreqLists/noun_freqs_decow14_16.txt does not exist\n"
     ]
    }
   ],
   "source": [
    "from germanetpy.path_based_relatedness_measures import PathBasedRelatedness\n",
    "from germanetpy.synset import WordCategory\n",
    "from germanetpy.icbased_similarity import ICBasedSimilarity\n",
    "\n",
    "relatedness_nouns = ICBasedSimilarity(germanet=germanet, \n",
    "                                      wordcategory=WordCategory.nomen,\n",
    "                                      path=frequencylist_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset(id=s34818, lexunits=Politiker, Politikerin)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_politikerIn = germanet.get_synsets_by_orthform(\"Politiker\")\n",
    "syn_politikerIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance_to_politician(synset):\n",
    "    syn_p = germanet.get_synsets_by_orthform(\"Politiker\").pop()\n",
    "    path_distance = synset.shortest_path_distance(syn_p)\n",
    "    return path_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from GermaNet Tutorial:\n",
    "def find_most_related_to_politician_path(list_syns):\n",
    "    # First, construct a path-based similarity object. \n",
    "    # The johannis_wurm and leber_trans synsets are maximally far apart among nouns:\n",
    "    johannis_wurm = germanet.get_synset_by_id(\"s49774\")\n",
    "    leber_trans = germanet.get_synset_by_id(\"s83979\")\n",
    "    relatedness_calculator = PathBasedRelatedness(germanet=germanet, category=WordCategory.nomen, max_len=35, max_depth=20, synset_pair=(johannis_wurm, leber_trans))\n",
    "    \n",
    "    syn_p = germanet.get_synsets_by_orthform(\"Politiker\").pop()\n",
    "    \n",
    "    res = {}\n",
    "    for syn in list_syns:\n",
    "        if syn.word_category == WordCategory.nomen:\n",
    "            res[syn] = relatedness_calculator.simple_path(syn, syn_p)\n",
    "    if(len(res)>0):\n",
    "        return max(res, key=res.get)\n",
    "    else:\n",
    "        return \"no nouns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_related_to_politician_ic(list_syns):\n",
    "    syn_p = germanet.get_synsets_by_orthform(\"Politiker\").pop()\n",
    "    res = {}\n",
    "    for syn in list_syns:\n",
    "        if syn.word_category == WordCategory.nomen:\n",
    "            res[syn] = relatedness_nouns.resnik(syn, syn_p, normalize=True)\n",
    "    if(len(res)>0):\n",
    "        return max(res, key=res.get)\n",
    "    else:\n",
    "        return \"no nouns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-3ebc1335923a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_bonus[\"best_syn\"] = data_bonus.apply(lambda row: find_most_related_to_politician_path(row[\"synsets_ger\"]) ,axis=1)\n",
      "<ipython-input-48-3ebc1335923a>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_bonus[\"best_syn_ic\"] = data_bonus.apply(lambda row: find_most_related_to_politician_ic(row[\"synsets_ger\"]) ,axis=1)\n"
     ]
    }
   ],
   "source": [
    "data_bonus[\"best_syn\"] = data_bonus.apply(lambda row: find_most_related_to_politician_path(row[\"synsets_ger\"]) ,axis=1)\n",
    "data_bonus[\"best_syn_ic\"] = data_bonus.apply(lambda row: find_most_related_to_politician_ic(row[\"synsets_ger\"]) ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=1360bdff-ae3e-40f9-b152-caccd7e0424c style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('1360bdff-ae3e-40f9-b152-caccd7e0424c').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suggestion_ger</th>\n",
       "      <th>synsets_ger</th>\n",
       "      <th>lexunits</th>\n",
       "      <th>hypernyms</th>\n",
       "      <th>lexunits_hypernyms</th>\n",
       "      <th>hyponyms</th>\n",
       "      <th>lexunits_hyponyms</th>\n",
       "      <th>city</th>\n",
       "      <th>synsets_check</th>\n",
       "      <th>best_syn</th>\n",
       "      <th>best_syn_ic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>[Synset(id=s23506, lexunits=American Airlines, AA), Synset(id=s26358, lexunits=Kot, Scheiße, Exkrement, Stuhl, Kacke, Kaka, Aa, Stuhlgang)]</td>\n",
       "      <td>[American Airlines, AA, Kot, Scheiße, Exkrement, Stuhl, Kacke, Kaka, Aa, Stuhlgang]</td>\n",
       "      <td>{Synset(id=s23493, lexunits=Fluggesellschaft, Luftfahrtgesellschaft, Fluglinie, Airline)}</td>\n",
       "      <td>[Fluggesellschaft, Luftfahrtgesellschaft, Fluglinie, Airline]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>Synset(id=s26358, lexunits=Kot, Scheiße, Exkrement, Stuhl, Kacke, Kaka, Aa, Stuhlgang)</td>\n",
       "      <td>Synset(id=s23506, lexunits=American Airlines, AA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abbruch</td>\n",
       "      <td>[Synset(id=s22422, lexunits=Abbruch, Beendigung, Beenden, Aufhören, Beendung), Synset(id=s106337, lexunits=Abbruch), Synset(id=s106285, lexunits=Abbruch), Synset(id=s106286, lexunits=Abbruch), Synset(id=s21303, lexunits=Abriss, Abbruch, Niederreißung)]</td>\n",
       "      <td>[Abbruch, Beendigung, Beenden, Aufhören, Beendung, Abbruch, Abbruch, Abbruch, Abriß, Abriss, Abbruch, Niederreißung]</td>\n",
       "      <td>{Synset(id=s21961, lexunits=Veränderung, Änderung)}</td>\n",
       "      <td>[Veränderung, Änderung]</td>\n",
       "      <td>{Synset(id=s121482, lexunits=Schulabbruch), Synset(id=s22427, lexunits=Ausschaltung, Ausschalten), Synset(id=s113518, lexunits=Bauabbruch), Synset(id=s72930, lexunits=Ablauf), Synset(id=s117289, lexunits=Startabbruch), Synset(id=s22429, lexunits=Abkehr, Abwendung), Synset(id=s100335, lexunits=Vertragsbeendigung), Synset(id=s123548, lexunits=Verbindungsabbruch), Synset(id=s22430, lexunits=Einstellung), Synset(id=s22517, lexunits=Vollendung), Synset(id=s22518, lexunits=Aufkündigung, Kündigung, Vertragsauflösung, Vertragskündigung, Vertragsaufhebung), Synset(id=s22432, lexunits=Schließung), Synset(id=s140469, lexunits=Fastenbrechen), Synset(id=s149250, lexunits=Aufenthaltsbeendigung), Synset(id=s22433, lexunits=Auflösung), Synset(id=s147580, lexunits=Kontaktabbruch), Synset(id=s92201, lexunits=Ausblendung), Synset(id=s101983, lexunits=Spielabbruch), Synset(id=s22435, lexunits=Niederlegung), Synset(id=s22436, lexunits=Entlassen, Entlassung), Synset(id=s106452, lexunits=Aufhebung), Synset(id=s112714, lexunits=Studienabbruch), Synset(id=s68923, lexunits=Endanflug), Synset(id=s22439, lexunits=Ableistung), Synset(id=s22423, lexunits=Niederschlagung), Synset(id=s22424, lexunits=Niederschlagung), Synset(id=s51777, lexunits=Ausstieg, Ausstiegsphase), Synset(id=s22425, lexunits=Abschaffung, Abschaffen)}</td>\n",
       "      <td>[Schulabbruch, Ausschaltung, Ausschalten, Bauabbruch, Ablauf, Startabbruch, Abkehr, Abwendung, Vertragsbeendigung, Verbindungsabbruch, Einstellung, Vollendung, Aufkündigung, Kündigung, Vertragsauflösung, Vertragskündigung, Vertragsaufhebung, Schließung, Fastenbrechen, Aufenthaltsbeendigung, Auflösung, Kontaktabbruch, Ausblendung, Spielabbruch, Niederlegung, Entlassen, Entlassung, Aufhebung, Studienabbruch, Endanflug, Ableistung, Niederschlagung, Niederschlagung, Ausstieg, Ausstiegsphase, Abschaffung, Abschaffen]</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>Synset(id=s106337, lexunits=Abbruch)</td>\n",
       "      <td>Synset(id=s106337, lexunits=Abbruch)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>abnehmen</td>\n",
       "      <td>[Synset(id=s53836, lexunits=abnehmen), Synset(id=s53908, lexunits=abchecken, abnehmen, begutachten, checken), Synset(id=s53807, lexunits=abnehmen), Synset(id=s56878, lexunits=abnehmen, herunternehmen, runternehmen), Synset(id=s60512, lexunits=abnehmen), Synset(id=s54392, lexunits=abnehmen), Synset(id=s54723, lexunits=abnehmen, abkaufen), Synset(id=s60521, lexunits=abnehmen), Synset(id=s52508, lexunits=wegnehmen, abnehmen, fortnehmen), Synset(id=s59787, lexunits=abnehmen)]</td>\n",
       "      <td>[abnehmen, abchecken, abnehmen, begutachten, checken, abnehmen, abnehmen, herunternehmen, runternehmen, abnehmen, abnehmen, abnehmen, abkaufen, abnehmen, wegnehmen, abnehmen, fortnehmen, abnehmen]</td>\n",
       "      <td>{Synset(id=s53835, lexunits=helfen)}</td>\n",
       "      <td>[helfen]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>no nouns</td>\n",
       "      <td>no nouns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>abschied</td>\n",
       "      <td>[Synset(id=s105682, lexunits=Abschied), Synset(id=s17481, lexunits=Abschied, Lebewohl, Verabschiedung)]</td>\n",
       "      <td>[Abschied, Abschied, Lebewohl, Verabschiedung]</td>\n",
       "      <td>{Synset(id=s22436, lexunits=Entlassen, Entlassung)}</td>\n",
       "      <td>[Entlassen, Entlassung]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>Synset(id=s105682, lexunits=Abschied)</td>\n",
       "      <td>Synset(id=s105682, lexunits=Abschied)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>adel</td>\n",
       "      <td>[Synset(id=s24212, lexunits=Adelsgeschlecht, Adel), Synset(id=s32247, lexunits=Adelstitel, Adel, Adelsbezeichnung)]</td>\n",
       "      <td>[Adelsgeschlecht, Adel, Adelstitel, Adel, Adelsbezeichnung]</td>\n",
       "      <td>{Synset(id=s24202, lexunits=Haus, Geschlecht, Dynastie, Familiendynastie, Familienclan)}</td>\n",
       "      <td>[Haus, Geschlecht, Dynastie, Familiendynastie, Familienclan]</td>\n",
       "      <td>{Synset(id=s93207, lexunits=Dienstadel), Synset(id=s136589, lexunits=Kriegeradel), Synset(id=s24215, lexunits=Hochadel), Synset(id=s111596, lexunits=Kleinadel), Synset(id=s65784, lexunits=Edelleute), Synset(id=s65171, lexunits=Ortsadel), Synset(id=s92515, lexunits=Gentry), Synset(id=s63065, lexunits=Uradel), Synset(id=s24216, lexunits=Bauernadel, Landadel), Synset(id=s87133, lexunits=Hofadel), Synset(id=s101528, lexunits=Erbadel), Synset(id=s122751, lexunits=Feudaladel), Synset(id=s24214, lexunits=Noblesse), Synset(id=s102967, lexunits=Reichsadel), Synset(id=s24217, lexunits=Stadtadel), Synset(id=s76879, lexunits=Amtsadel)}</td>\n",
       "      <td>[Dienstadel, Kriegeradel, Hochadel, Kleinadel, Edelleute, Ortsadel, Gentry, Uradel, Bauernadel, Landadel, Hofadel, Erbadel, Feudaladel, Noblesse, Reichsadel, Stadtadel, Amtsadel]</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>Synset(id=s32247, lexunits=Adelstitel, Adel, Adelsbezeichnung)</td>\n",
       "      <td>Synset(id=s24212, lexunits=Adelsgeschlecht, Adel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>zirkus</td>\n",
       "      <td>[Synset(id=s108415, lexunits=Zirkus), Synset(id=s73248, lexunits=Zirkus, Zirkusunternehmen), Synset(id=s17960, lexunits=Zirkus), Synset(id=s14333, lexunits=Rabatz, Radau, Trubel, Theater, Zirkus)]</td>\n",
       "      <td>[Circus, Zirkus, Circus, Zirkus, Zirkusunternehmen, Circus, Zirkus, Rabatz, Radau, Trubel, Theater, Zirkus]</td>\n",
       "      <td>{Synset(id=s42745, lexunits=Arena, Stadion)}</td>\n",
       "      <td>[Arena, Stadion]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>Synset(id=s108415, lexunits=Zirkus)</td>\n",
       "      <td>Synset(id=s108415, lexunits=Zirkus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>zitat</td>\n",
       "      <td>[Synset(id=s32274, lexunits=Zitat), Synset(id=s32501, lexunits=Zitat)]</td>\n",
       "      <td>[Zitat, Zitat]</td>\n",
       "      <td>{Synset(id=s32267, lexunits=Redewendung, Idiom, Redensart, Wendung)}</td>\n",
       "      <td>[Redewendung, Idiom, Redensart, Wendung]</td>\n",
       "      <td>{Synset(id=s137738, lexunits=Selbstzitat)}</td>\n",
       "      <td>[Selbstzitat]</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>Synset(id=s32501, lexunits=Zitat)</td>\n",
       "      <td>Synset(id=s32274, lexunits=Zitat)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>zug</td>\n",
       "      <td>[Synset(id=s40992, lexunits=Zugkraft, Zug), Synset(id=s41350, lexunits=Luftzug, Zug, Luft), Synset(id=s17675, lexunits=Zug), Synset(id=s8724, lexunits=Eisenbahn, Eisenbahnzug, Zug, Bahn), Synset(id=s14348, lexunits=Gesichtszug, Zug), Synset(id=s76189, lexunits=Zug), Synset(id=s21974, lexunits=Ziehen, Zug), Synset(id=s76183, lexunits=Zug), Synset(id=s109599, lexunits=Zug), Synset(id=s76184, lexunits=Zug), Synset(id=s14044, lexunits=Charaktereigenschaft, Charakterzug, Zug, Wesenszug, Charaktermerkmal), Synset(id=s8959, lexunits=Lastzug, Zug), Synset(id=s76185, lexunits=Zug), Synset(id=s44336, lexunits=Zug)]</td>\n",
       "      <td>[Zugkraft, Zug, Luftzug, Zug, Luft, Zug, Eisenbahn, Eisenbahnzug, Zug, Bahn, Gesichtszug, Zug, Zug, Ziehen, Zug, Zug, Zug, Zug, Charaktereigenschaft, Charakterzug, Zug, Wesenszug, Charaktermerkmal, Lastzug, Zug, Zug, Zug]</td>\n",
       "      <td>{Synset(id=s40976, lexunits=Kraft)}</td>\n",
       "      <td>[Kraft]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>Synset(id=s109599, lexunits=Zug)</td>\n",
       "      <td>Synset(id=s17675, lexunits=Zug)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>zukunft</td>\n",
       "      <td>[Synset(id=s51054, lexunits=Zukunft, Vorzeitigkeit, Hinkunft), Synset(id=s64962, lexunits=Futur, Zukunft, Futurum)]</td>\n",
       "      <td>[Zukunft, Vorzeitigkeit, Hinkunft, Futur, Zukunft, Futurum]</td>\n",
       "      <td>{Synset(id=s51051, lexunits=Zeitstufe)}</td>\n",
       "      <td>[Zeitstufe]</td>\n",
       "      <td>{Synset(id=s139797, lexunits=Energiezukunft), Synset(id=s22920, lexunits=Nachwelt), Synset(id=s100061, lexunits=Vorweg)}</td>\n",
       "      <td>[Energiezukunft, Nachwelt, Vorweg]</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>Synset(id=s51054, lexunits=Zukunft, Vorzeitigkeit, Hinkunft)</td>\n",
       "      <td>Synset(id=s51054, lexunits=Zukunft, Vorzeitigkeit, Hinkunft)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>zusammenbruch</td>\n",
       "      <td>[Synset(id=s17119, lexunits=Zusammenbruch, Crash), Synset(id=s17538, lexunits=Kollaps, Zusammenbruch)]</td>\n",
       "      <td>[Zusammenbruch, Crash, Kollaps, Zusammenbruch]</td>\n",
       "      <td>{Synset(id=s21256, lexunits=Zerstörung, Destruktion)}</td>\n",
       "      <td>[Zerstörung, Destruktion]</td>\n",
       "      <td>{Synset(id=s69105, lexunits=Börsencrash)}</td>\n",
       "      <td>[Börsencrash]</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>Synset(id=s17538, lexunits=Kollaps, Zusammenbruch)</td>\n",
       "      <td>Synset(id=s17119, lexunits=Zusammenbruch, Crash)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "     suggestion_ger                                        synsets_ger  \\\n",
       "0                aa  [Synset(id=s23506, lexunits=American Airlines,...   \n",
       "6           abbruch  [Synset(id=s22422, lexunits=Abbruch, Beendigun...   \n",
       "15         abnehmen  [Synset(id=s53836, lexunits=abnehmen), Synset(...   \n",
       "18         abschied  [Synset(id=s105682, lexunits=Abschied), Synset...   \n",
       "26             adel  [Synset(id=s24212, lexunits=Adelsgeschlecht, A...   \n",
       "...             ...                                                ...   \n",
       "3741         zirkus  [Synset(id=s108415, lexunits=Zirkus), Synset(i...   \n",
       "3742          zitat  [Synset(id=s32274, lexunits=Zitat), Synset(id=...   \n",
       "3752            zug  [Synset(id=s40992, lexunits=Zugkraft, Zug), Sy...   \n",
       "3753        zukunft  [Synset(id=s51054, lexunits=Zukunft, Vorzeitig...   \n",
       "3755  zusammenbruch  [Synset(id=s17119, lexunits=Zusammenbruch, Cra...   \n",
       "\n",
       "                                               lexunits  \\\n",
       "0     [American Airlines, AA, Kot, Scheiße, Exkremen...   \n",
       "6     [Abbruch, Beendigung, Beenden, Aufhören, Beend...   \n",
       "15    [abnehmen, abchecken, abnehmen, begutachten, c...   \n",
       "18       [Abschied, Abschied, Lebewohl, Verabschiedung]   \n",
       "26    [Adelsgeschlecht, Adel, Adelstitel, Adel, Adel...   \n",
       "...                                                 ...   \n",
       "3741  [Circus, Zirkus, Circus, Zirkus, Zirkusunterne...   \n",
       "3742                                     [Zitat, Zitat]   \n",
       "3752  [Zugkraft, Zug, Luftzug, Zug, Luft, Zug, Eisen...   \n",
       "3753  [Zukunft, Vorzeitigkeit, Hinkunft, Futur, Zuku...   \n",
       "3755     [Zusammenbruch, Crash, Kollaps, Zusammenbruch]   \n",
       "\n",
       "                                              hypernyms  \\\n",
       "0     {Synset(id=s23493, lexunits=Fluggesellschaft, ...   \n",
       "6     {Synset(id=s21961, lexunits=Veränderung, Änder...   \n",
       "15                 {Synset(id=s53835, lexunits=helfen)}   \n",
       "18    {Synset(id=s22436, lexunits=Entlassen, Entlass...   \n",
       "26    {Synset(id=s24202, lexunits=Haus, Geschlecht, ...   \n",
       "...                                                 ...   \n",
       "3741       {Synset(id=s42745, lexunits=Arena, Stadion)}   \n",
       "3742  {Synset(id=s32267, lexunits=Redewendung, Idiom...   \n",
       "3752                {Synset(id=s40976, lexunits=Kraft)}   \n",
       "3753            {Synset(id=s51051, lexunits=Zeitstufe)}   \n",
       "3755  {Synset(id=s21256, lexunits=Zerstörung, Destru...   \n",
       "\n",
       "                                     lexunits_hypernyms  \\\n",
       "0     [Fluggesellschaft, Luftfahrtgesellschaft, Flug...   \n",
       "6                               [Veränderung, Änderung]   \n",
       "15                                             [helfen]   \n",
       "18                              [Entlassen, Entlassung]   \n",
       "26    [Haus, Geschlecht, Dynastie, Familiendynastie,...   \n",
       "...                                                 ...   \n",
       "3741                                   [Arena, Stadion]   \n",
       "3742           [Redewendung, Idiom, Redensart, Wendung]   \n",
       "3752                                            [Kraft]   \n",
       "3753                                        [Zeitstufe]   \n",
       "3755                          [Zerstörung, Destruktion]   \n",
       "\n",
       "                                               hyponyms  \\\n",
       "0                                                    {}   \n",
       "6     {Synset(id=s121482, lexunits=Schulabbruch), Sy...   \n",
       "15                                                   {}   \n",
       "18                                                   {}   \n",
       "26    {Synset(id=s93207, lexunits=Dienstadel), Synse...   \n",
       "...                                                 ...   \n",
       "3741                                                 {}   \n",
       "3742         {Synset(id=s137738, lexunits=Selbstzitat)}   \n",
       "3752                                                 {}   \n",
       "3753  {Synset(id=s139797, lexunits=Energiezukunft), ...   \n",
       "3755          {Synset(id=s69105, lexunits=Börsencrash)}   \n",
       "\n",
       "                                      lexunits_hyponyms   city  synsets_check  \\\n",
       "0                                                    []  False              2   \n",
       "6     [Schulabbruch, Ausschaltung, Ausschalten, Baua...  False              5   \n",
       "15                                                   []  False             10   \n",
       "18                                                   []  False              2   \n",
       "26    [Dienstadel, Kriegeradel, Hochadel, Kleinadel,...  False              2   \n",
       "...                                                 ...    ...            ...   \n",
       "3741                                                 []  False              4   \n",
       "3742                                      [Selbstzitat]  False              2   \n",
       "3752                                                 []  False             14   \n",
       "3753                 [Energiezukunft, Nachwelt, Vorweg]  False              2   \n",
       "3755                                      [Börsencrash]  False              2   \n",
       "\n",
       "                                               best_syn  \\\n",
       "0     Synset(id=s26358, lexunits=Kot, Scheiße, Exkre...   \n",
       "6                  Synset(id=s106337, lexunits=Abbruch)   \n",
       "15                                             no nouns   \n",
       "18                Synset(id=s105682, lexunits=Abschied)   \n",
       "26    Synset(id=s32247, lexunits=Adelstitel, Adel, A...   \n",
       "...                                                 ...   \n",
       "3741                Synset(id=s108415, lexunits=Zirkus)   \n",
       "3742                  Synset(id=s32501, lexunits=Zitat)   \n",
       "3752                   Synset(id=s109599, lexunits=Zug)   \n",
       "3753  Synset(id=s51054, lexunits=Zukunft, Vorzeitigk...   \n",
       "3755  Synset(id=s17538, lexunits=Kollaps, Zusammenbr...   \n",
       "\n",
       "                                            best_syn_ic  \n",
       "0     Synset(id=s23506, lexunits=American Airlines, AA)  \n",
       "6                  Synset(id=s106337, lexunits=Abbruch)  \n",
       "15                                             no nouns  \n",
       "18                Synset(id=s105682, lexunits=Abschied)  \n",
       "26    Synset(id=s24212, lexunits=Adelsgeschlecht, Adel)  \n",
       "...                                                 ...  \n",
       "3741                Synset(id=s108415, lexunits=Zirkus)  \n",
       "3742                  Synset(id=s32274, lexunits=Zitat)  \n",
       "3752                    Synset(id=s17675, lexunits=Zug)  \n",
       "3753  Synset(id=s51054, lexunits=Zukunft, Vorzeitigk...  \n",
       "3755   Synset(id=s17119, lexunits=Zusammenbruch, Crash)  \n",
       "\n",
       "[451 rows x 11 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bonus.to_csv(\"data_03.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
